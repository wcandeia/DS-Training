{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo dados com a biblioteca Pandas\n",
    "https://campus.datacamp.com/courses/kaggle-python-tutorial-on-machine-learning/getting-started-with-python?ex=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando o Titanic afundou, 1502 dos 2224 passageiros e tripulantes morreram. Uma das principais razões para esta grande quantidade de baixas foi a falta de botes salva-vidas neste autoproclamado navio \"inafundável\".\n",
    "\n",
    "Aqueles que assistiram ao filme sabem que alguns indivíduos eram mais propensos a sobreviver ao naufrágio (Rose sortuda) do que outros (o pobre Jack). Neste curso, você aprenderá como aplicar técnicas de aprendizado de máquina para prever as chances de um passageiro sobreviver usando o Python.\n",
    "\n",
    "Vamos começar carregando o conjunto de treinamento e testes em seu ambiente Python. Você usará o conjunto de treinamento para criar seu modelo e o conjunto de testes para validá-lo. Os dados são armazenados na web como `arquivos csv`; suas URLs já estão disponíveis como sequências de caracteres no código de amostra. Você pode carregar estes dados com o método `read_csv()` da biblioteca Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os conjuntos de treino e teste para criar dois DataFrames\n",
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "\n",
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "#test_url = \"/Users/wcandeia/Documents/Codes/Notebooks/Titanic/test.csv\"\n",
    "test = pd.read_csv(test_url)\n",
    "\n",
    "# Imprimindo as primeiras linhas dos conjuntos de teste e treino do dataframe\n",
    "print(train.head(3))\n",
    "print(test.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo seus dados\n",
    "Antes de começar com a análise, é importante entender a estrutura dos seus dados. Ambos `test` e `train` são objetos DataFrame, o modo como Pandas representa os conjuntos de dados. Você pode explorar facilmente um DataFrame usando o método `.describe()` . `.describe()` resume as colunas/características do DataFrame, incluindo a contagem de observações, média, máx e assim por diante. Outra dica útil é observar as dimensões do DataFrame. Isto é feito solicitando o atributo `.shape` do seu objeto DataFrame. (ex. `seus_dados.shape`)\n",
    "\n",
    "O conjunto de treinamento e de teste já está disponível no espaço de trabalho (workplace), como `train` e` test`. Aplique o método `.describe ()` e imprima o atributo `.shape` do conjunto de treinamento. Qual das seguintes afirmações está correta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O conjunto de treinamento tem 891 observações e 12 variáveis, a contagem total para idade é de 714.\n",
    "train.shape\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rose vs Jack, ou Feminino vs Masculino\n",
    "Quantas pessoas em seu conjunto de dados de treinamento sobreviveram ao desastre do Titanic? Para ver isso, você pode usar o método `value_counts ()` em combinação com a notação de colchetes padrão para selecionar uma única coluna de um DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```# números absolutos\n",
    "train[\"Survived\"].value_counts()```\n",
    "\n",
    "```# porcentagens\n",
    "train[\"Survived\"].value_counts(normalize = True)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você executar esses comandos no console, observará que 549 pessoas morreram (62%) e 342 sobreviveram (38%). Uma maneira simples de prever heuristicamente poderia ser: \"maioria ganha\". Isto significa que você vai prever cada observação invisível para não sobreviver.\n",
    "\n",
    "Para mergulhar um pouco mais fundo, podemos realizar contagens e cálculos percentuais semelhantes em subconjuntos da coluna Survived. Por exemplo, talvez gênero também pudesse desempenhar um papel? Você pode explorar isso usando o método `.value_counts ()` para uma comparação bidirecional sobre o número de homens e mulheres que sobreviveram, com esta sintaxe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts()\n",
    "train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts() ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter proporções, você pode passar novamente no argumento normalize = True para o método `.value_counts ()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule e imprima as taxas de sobrevivência em números absolutos usando o método values_counts ().\n",
    "# Passageiros que sobreviveram vs passageiros que faleceram\n",
    "print(train[\"Survived\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule e imprima as taxas de sobrevivência como proporções configurando o argumento normalize como True.\n",
    "print(train[\"Survived\"].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repita os mesmos cálculos, mas em subconjuntos de sobrevivências baseadas em sexo.\n",
    "# Homens que sobreviveram vs homens que faleceram\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mulheres que sobreviveram vs mulheres que faleceram\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxa de sobrevivência masculina normalizada\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxa de sobrevivência feminina normalizada\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A idade influencia em algo?\n",
    "Outra variável que pode influenciar a sobrevivência é a idade; uma vez que é provável que as crianças foram salvas primeiro. Você pode testar isso criando uma nova coluna com uma variável categórica `Child`. 'Child' terá o valor 1 nos casos em que a idade for menor que 18 e o valor 0 nos casos em que a idade for maior ou igual a 18.\n",
    "\n",
    "Para adicionar essa nova variável, você precisa fazer duas coisas (i) criar uma nova coluna e (ii) fornecer os valores para cada observação (ou seja, linha) com base na idade do passageiro.\n",
    "\n",
    "Adicionar uma nova coluna com Pandas em Python é fácil e pode ser feito através da seguinte sintaxe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```your_data[\"new_var\"] = 0```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código criaria uma nova coluna no DataFrame `train` chamado `new_var` com `0` para cada observação.\n",
    "\n",
    "Para definir os valores com base na idade do passageiro, você faz um teste booleano dentro do operador de colchetes. Com o operador `[]`, você cria um subconjunto de linhas e atribui um valor a uma determinada variável desse subconjunto de observações. Por exemplo,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` train[\"new_var\"][train[\"Fare\"] > 10] = 1 ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daria um valor de `1` à variável `new_var` para o subconjunto de passageiros com tarifas superiores a `10`. Lembre-se que `new_var` tem um valor de `0` para todos os outros valores (incluindo valores omissos).\n",
    "\n",
    "Uma nova coluna chamada `Child` no dataframe ` train` foi criada para você e recebe o valor `NaN` para todas as observações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina os valores de Child para 1 se a idade do passageiro for menor que 18 anos.\n",
    "# Crie a coluna Child e a atribua 'NaN'\n",
    "train[\"Child\"] = float('NaN')\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign 1 to passengers under 18, 0 to those 18 or older. Print the new column.\n",
    "# train[\"Child\"][train[\"Age\"] < 18] = 1\n",
    "# train[\"Child\"][train[\"Age\"] >= 18] = 0\n",
    "# print(train[\"Child\"])\n",
    "train[\"Child\"][train[\"Age\"] >= 50] = 4\n",
    "train[\"Child\"][train[\"Age\"] < 50] = 3\n",
    "train[\"Child\"][train[\"Age\"] < 18] = 2\n",
    "train[\"Child\"][train[\"Age\"] < 13] = 1\n",
    "train[\"Child\"][train[\"Age\"] < 5] = 0\n",
    "#print(train[\"Age\"], train[\"Child\"])\n",
    "#print(train[\"Child\"])\n",
    "#print(train[50:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print normalized Survival Rates for passengers under 18\n",
    "# print(train[\"Survived\"][train[\"Child\"] == 1].value_counts(normalize = True))\n",
    "\n",
    "# Print normalized Survival Rates for passengers 18 or older\n",
    "# print(train[\"Survived\"][train[\"Child\"] == 0].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir taxas de sobrevivência normalizadas\n",
    "#  para passageiros menores que 13 e maiores que 5\n",
    "print(train[\"Survived\"][train[\"Child\"] == 0].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir taxas de sobrevivência normalizadas\n",
    "#  para passageiros menores que cinco\n",
    "print(train[\"Survived\"][train[\"Child\"] == 0].value_counts(normalize = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir taxas de sobrevivência normalizadas\n",
    "#  para passageiros menores que 13 e maiores que 5\n",
    "print(train[\"Survived\"][train[\"Child\"] == 4].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeira Predição\n",
    "\n",
    "Em um dos exercícios anteriores, você descobriu que, no seu conjunto de treinamento, o sexo feminino tinha mais de 50% de chance de sobreviver e o sexo masculino tinha menos de 50% de chance de sobreviver. Portanto, você pode usar essa informação para a sua primeira previsão: todas as pessoas do sexo feminino no conjunto de testes sobrevivem e todos do sexo masculino no mesmo conjunto morrem.\n",
    "\n",
    "Você utiliza seu conjunto de testes para validar suas previsões. Você pode ter visto que, ao contrário do conjunto de treinamento, o conjunto de testes não possui uma coluna `Survived`. Você adiciona essa coluna usando seus valores previstos. Em seguida, ao enviar seus resultados, o Kaggle usará **sua** variável (= suas previsões) para avaliar seu desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma cópia do conjunto de testes: test_one\n",
    "test_one = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione uma coluna adicional, Survived, e inicialize com zero.\n",
    "# Inicialize uma coluna Survived com 0\n",
    "test_one[\"Survived\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina Survived com 1 se Sex for igual a \"female\" e imprima a coluna `Survived` de` test_one`\n",
    "test_one[\"Survived\"][test_one[\"Sex\"] == 'female'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprima a coluna Survived de previsões do conjunto de dados test_one.\n",
    "#print(test_one[\"Survived\"])\n",
    "print(test_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one[\"PassengerId\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = test_one[\"PassengerId\"].values, test_one[\"Survived\"].values\n",
    "submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução as árvores de decisão\n",
    "\n",
    "No capítulo anterior, você fez toda uma segmentação para encontrar subconjuntos que têm uma chance maior de sobreviver. Uma árvore de decisão automatiza esse processo para você e gera um modelo de classificação ou classificador.\n",
    "\n",
    "Conceitualmente, o algoritmo da árvore de decisão começa com todos os dados no nó raiz e varre todas as variáveis para a melhor divisão. Quando uma variável é escolhida, você faz a divisão e desce um nível (ou um nó) e repete. Os nós finais na parte inferior da árvore de decisão são conhecidos como nós terminais, e o voto majoritário das observações nesse nó determina como prever novas observações que param nesse nó terminal.\n",
    "\n",
    "Primeiro, vamos importar as bibliotecas necessárias:\n",
    "\n",
    "    Import the numpy library as np\n",
    "    From sklearn import the tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe a biblioteca Numpy\n",
    "import numpy as np\n",
    "# Importe 'tree' da biblioteca scikit-learn\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpando e formatando seus dados\n",
    "\n",
    "Antes de começar a construir suas árvores, você precisa sujar as mãos e limpar os dados para poder usar todos os recursos disponíveis para você. No primeiro capítulo, vimos que a variável `Age` tinha algum valor faltante (missing value). A falta de dados por si só já é um assunto para investigar mais profundamente, mas nós usaremos uma técnica de imputação simples onde substituímos cada valor perdido com a `mediana` dos valores presentes.\n",
    "\n",
    "    train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "\n",
    "Outro problema é que as variáveis `Sex` e` Embarked` são categóricas **mas** em formato não numérico. Assim, precisaremos atribuir a cada classe um inteiro único para que o Python possa manipular as informações. `Embarked` também tem alguns valores perdidos que você deve imputar com a classe mais comum de embarque, que é `\" S \"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "test_one[\"Age\"] = test_one[\"Age\"].fillna(test_one[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentem\n",
    "# Testem após a linha anterior para ver o que acontece\n",
    "# train[\"Age\"] = train[\"Age\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converta os grupos mulheres e homens para a forma inteira\n",
    "# Atribua o valor inteiro 1 para todas as mulheres\n",
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n",
    "test_one[\"Sex\"][test_one[\"Sex\"] == \"male\"] = 0\n",
    "test_one[\"Sex\"][test_one[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "#train[\"Sex\"]\n",
    "#test_one[\"Sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Imputar\" a variável Embarked\n",
    "# \"Imputar\" os missing values em Embarked com classe S. Use o método .fillna().\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "test_one[\"Embarked\"] = test_one[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitua cada classe de Embarked com inteiros únicos. 0 para S, 1 para C, e 2 para Q.\n",
    "# Converta as classes de Embarked para inteiros\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitua cada classe de Embarked com inteiros únicos. 0 para S, 1 para C, e 2 para Q.\n",
    "# Converta as classes de Embarked para inteiros\n",
    "test_one[\"Embarked\"][test_one[\"Embarked\"] == \"S\"] = 0\n",
    "test_one[\"Embarked\"][test_one[\"Embarked\"] == \"C\"] = 1\n",
    "test_one[\"Embarked\"][test_one[\"Embarked\"] == \"Q\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostre as colunas Sex e Embarked\n",
    "print(train[\"Sex\"])\n",
    "print(train[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando sua primeira árvore de decisão\n",
    "\n",
    "Utilizando as bibliotecas `scikit-learn` e `numpy` construiremos nosso primeiro modelo de árvore de decisão. `scikit-learn` pode ser utilizada para criar objetos tipo árvore a partir da classe `DecisionTreeClassifier`. Os métodos que utilizaremos recebem arrays `numpy` como entradas e então precisamos acessar nossas entradas com o `DataFrame` que já temos. Construímos a árvore de decisão da seguinte forma:\n",
    "\n",
    "* target: Um array unidimensional `numpy` contendo o alvo/resposta do conjunto de treinamento. (Survival neste caso)\n",
    "* features: Um array multidimensional `numpy` contendo as features/preditores do conjunto de treinamento. (ex. Sex, Age)\n",
    "\n",
    "Veja o trecho de código abaixo para entender como deve parecer essa etapa:\n",
    "\n",
    "    target = train[\"Survived\"].values\n",
    "\n",
    "    features = train[[\"Sex\", \"Age\"]].values\n",
    "\n",
    "    my_tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "    my_tree = my_tree.fit(features, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma rápida de ver o resultado da árvore de decisão é ver qual a importância das features incluídas no treinamento. Isto é feito requisitando o atributo `.feature_importances_ attribute` do seu objeto (da árvore). Outra métrica rápida é medir a acurácia que você pode computar utilizando a função `.score()` com `features_one` e `target` como argumentos.\n",
    "\n",
    "Certo?! É hora de você construir sua primeira árvore de decisão em Python! Os dados de treinamento `train` e de teste `testing` já estão disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar as informações sobre os dados de treinamento\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construa os arrays numpy de alvo/objetivo `target` e `features_one`. \n",
    "# O objetivo é baseado na coluna Survived em train. \n",
    "# O vetor com a entrada baseia-se nas variáveis Passenger, Class, Sex, Age, e Passenger Fare\n",
    "# Crie os arrays numpy: target, features_one\n",
    "target = train[\"Survived\"].values\n",
    "features_one = train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Embarked\"]].values\n",
    "print(features_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construa a árvore de decisão my_tree_one para predizer a sobrevivência utilizando:\n",
    "#  features_one e target\n",
    "my_tree_one = tree.DecisionTreeClassifier()\n",
    "my_tree_one = my_tree_one.fit(features_one, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veja a importância das variáveis/features na sua árvore e calcule a pontuação\n",
    "# Veja a importância e pontuação das features\n",
    "print(my_tree_one.feature_importances_)\n",
    "#print(my_tree_one.score(features_one, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretando sua árvore de decisão\n",
    "\n",
    "O atributo `feature_importances_` torna simples interpretar o que os preditores representam.\n",
    "Com base em sua árvore de decisão, qual variável é mais importante em determinar se um passageiro sobreviveu ou não? Seu modelo (`my_tree_one`) é disponível no console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resp: `Sex`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição e submissão no Kaggle\n",
    "\n",
    "Para submeter no Kaggle você precisa predizer as taxas de sobrevivência com base no conjunto de teste.  Com nossa árvore de decisão, nós podemos fazer uso de algumas funções simples para \"gerar\" nossa resposta.\n",
    "\n",
    "Primeiro, utilize o método `.predict()`. Você adiciona o modelo (`my_tree_one`), os valores das features do conjunto de dados para as predições que precisam ser feitas (`test`). Para extrair as features precisamos criar um array `numpy` da mesma maneira como fizemos no treinamento do modelo. No entanto, necessitamos ter cuidado com uma pequena mas importante questão. Falta algum valor em `Fare` que precisa ser \"imputado\".\n",
    "\n",
    "Depois, você precisa ter certeza que sua saída está de acordo com os requisitos de submissão do Kaggle: um arquivo csv com exatamente 418 entradas e duas colunas: `PassengerId` e `Survived`. Então utilize o código advindo para fazer um novo `DataFrame` utilizando `DataFrame()`, e cri um arquivo csv usando o método `to_csv()` do Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute o missing value de Fare na linha 153 com a mediana da coluna.\n",
    "test_one.Fare[152] = test_one[\"Fare\"].median()\n",
    "print(test_one.Fare[152])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraia os atributos/features do conjunto de teste: Pclass, Sex, Age, Fare, SibSp e Embarked.\n",
    "test_features = test_one[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Embarked\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça sua predição utilizando o conjunto de teste\n",
    "# test_one[\"Sex\"]\n",
    "my_prediction = my_tree_one.predict(test_features)\n",
    "my_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Crie um data frame com duas colunas: PassengerId e Survived.\n",
    "# Survived contém suas predições\n",
    "PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique se o seu data frame possui 418 entradas\n",
    "print(my_solution.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salve sua solução em um arquivo csv com o nome my_solution_one.csv\n",
    "my_solution.to_csv(\"my_solution_one.csv\", index_label = [\"PassengerId\"])\n",
    "print(my_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting e como controlar isso\n",
    "\n",
    "Quando você criou sua primeira árvore de decisão, os argumentos padrão para `max_depth` e `min_samples_split` foram configurados como `None`. Isso significa que nenhum limite para a profundidade de sua árvore foi definido. Isso é uma coisa boa, certo? Não tão rápido. Provavelmente temos um overfitting. Isso significa que, embora seu modelo descreva os dados de treinamento muito bem, ele não generaliza para novos dados, o que é francamente o ponto de predição. Basta olhar para os resultados de envio do Kaggle para o modelo simples baseado em gênero (Gender) e a árvore de decisão complexa. Qual é o melhor?\n",
    "\n",
    "Talvez possamos melhorar o modelo de sobreajuste criando um modelo menos complexo? Em `DecisionTreeRegressor`, a profundidade do nosso modelo é definida por dois parâmetros: - o parâmetro `max_depth` determina quando a divisão da árvore de decisão finaliza. - o parâmetro `min_samples_split` monitora a quantidade de observações em um intervalo. Se um certo limite não for atingido (por exemplo, mínimo de 10 passageiros), nenhuma divisão adicional pode ser feita.\n",
    "\n",
    "Ao limitar a complexidade de sua árvore de decisão, você aumentará sua generalidade e, portanto, sua utilidade para previsões!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluir: irmãos/cônjuges a bordo, pais/filhos a bordo e atributos Embarked em um novo conjunto de atributos.\n",
    "# Criar uma nova matriz com os recursos adicionados: features_two\n",
    "features_two = train[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste sua segunda árvore my_tree_two com os novos atributos e controle a complexidade do modelo alternando ...\n",
    "# ...os argumentos max_depth e min_samples_split.\n",
    "# Controle o sobreajuste (overfitting) definindo \"max_depth\" para 10 e \"min_samples_split\" para 5: my_tree_two\n",
    "\n",
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "my_tree_two = tree.DecisionTreeClassifier(max_depth = max_depth,\n",
    "                                          min_samples_split = min_samples_split,\n",
    "                                          random_state = 1)\n",
    "my_tree_two = my_tree_two.fit(features_two, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar o escore da nova árvore de decisão\n",
    "print(my_tree_two.score(features_two, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submeter a segunda solução!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature-engineering para nosso conjunto de dados do Titanic\n",
    "\n",
    "Data Science é uma arte que se beneficia de um elemento humano. Vamos trabalhar com feature engineering: desenvolva criativamente seus próprios atributos combinando as diferentes variáveis existentes.\n",
    "\n",
    "Embora feature engineering seja uma disciplina em si, muito ampla para ser abordada aqui em detalhes, você verá um exemplo simples criando seu próprio novo atributo preditivo: `family_size`.\n",
    "\n",
    "Uma suposição válida é que famílias maiores precisam de mais tempo para se reunir em um navio que está naufragando e, portanto, têm menor probabilidade de sobreviver. O tamanho da família é determinado pelas variáveis `SibSp` e `Parch`, que indicam o número de membros da família com quem um determinado passageiro está viajando. Então, ao fazer featuring engineering, você adiciona uma nova variável `family_size`, que é a soma de `SibSp` e `Parch` mais um (a própria observação), ao conjunto `test` e `train`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um novo conjunto de treinamento train_two que difere de train apenas por ter uma coluna extra ...\n",
    "# ... com sua variável family_size.\n",
    "# Crie train_two com a recém-definida family_size\n",
    "\n",
    "train_two = train.copy()\n",
    "train_two[\"family_size\"] = train[\"SibSp\"] + train[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione family_size além de ...\n",
    "# ... Pclass, Sex, Age, Fare, SibSp e Parch para features_three.\n",
    "# Crie um novo conjunto de atributos com esses elementos\n",
    "\n",
    "features_three = train_two[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Parch\", \"family_size\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma nova árvore de decisão como my_tree_three e ajuste a árvore de decisão com seu novo conjunto features_three.\n",
    "# Em seguida, verifique a pontuação da árvore de decisão.\n",
    "# Defina o classificador de árvore e ajuste o modelo\n",
    "\n",
    "my_tree_three = tree.DecisionTreeClassifier()\n",
    "my_tree_three = my_tree_three.fit(features_three, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mostrar o escore dessa árvore de decisão\n",
    "print(my_tree_three.score(features_three, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submeter a terceira solução!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uma análise com random forest em Python\n",
    "\n",
    "Um estudo detalhado de Random Forests levaria este estudo de caso um pouco longe demais. No entanto, como é uma técnica de aprendizado de máquina usada com frequência, obter um entendimento geral do Python não fará mal.\n",
    "\n",
    "Em termos gerais, a técnica Random Forest lida com o problema de overfitting que você enfrentou com as árvores de decisão. Ela desenvolve várias árvores de classificação (muito profundas) usando o conjunto de treinamento. No momento da predição, cada árvore é usada para fazer uma previsão e cada resultado é contado como um voto. Por exemplo, se você treinou 3 árvores com 2 dizendo que um passageiro no conjunto de teste sobreviverá e 1 dizendo que não, o passageiro será classificado como um sobrevivente. Essa abordagem de overtraining de árvores, mas tendo o voto da maioria contado como a decisão de classificação real, evita overfitting.\n",
    "\n",
    "Construir uma floresta aleatória em Python é quase o mesmo que construir uma árvore de decisão. Existem duas diferenças principais, no entanto. Em primeiro lugar, uma classe diferente é usada. E em segundo lugar, um novo argumento é necessário. Além disso, precisamos importar a biblioteca necessária do `scikit-learn`.\n",
    "\n",
    "* Use a classe `RandomForestClassifier()` em vez da classe `DecisionTreeClassifier()`.\n",
    "* `n_estimators` precisa ser definido ao usar a classe `RandomForestClassifier()`. Este argumento permite que você defina o número de árvores que deseja plantar e calcular a média.\n",
    "\n",
    "Os dados de treinamento e teste mais recentes estão pré-carregados para você."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe `RandomForestClassifier`\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queremos as variáveis Pclass, Age, Sex, Fare,SibSp, Parch e Embarked\n",
    "features_forest = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir o preditor com n_estimators igual a 100.\n",
    "# Construindo e ajustando my_forest\n",
    "forest = RandomForestClassifier(max_depth = 10,\n",
    "                                min_samples_split=2,\n",
    "                                n_estimators = 100,\n",
    "                                random_state = 1)\n",
    "# Ajuste seu modelo de floresta aleatória com entradas features_forest e target.\n",
    "my_forest = forest.fit(features_forest, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostre a pontuação ajustada\n",
    "print(my_forest.score(features_forest, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule as previsões do classificador nos atributos do conjunto de teste selecionado.\n",
    "# Calcule as previsões em nossos recursos de conjunto de teste e imprima o comprimento do vetor de previsão\n",
    "\n",
    "test_features = test_one[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "pred_forest = my_forest.predict(test_features)\n",
    "print(len(pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretando e comparando\n",
    "\n",
    "Lembra como olhamos para o atributo `.feature_importances_` para as árvores de decisão? Bem, você também pode solicitar o mesmo atributo de sua floresta aleatória e interpretar a relevância das variáveis incluídas. Você também pode querer comparar os modelos de uma maneira rápida e fácil. Para isso, podemos usar o método `.score ()`. O método `.score ()` pega os atributos `data` e o vetor `target` e calcula a precisão de `mean` do seu modelo. Você pode aplicar este método às árvores **forest** e **individual**. Lembre-se de que essa medida deve ser alta, mas não extrema, porque isso seria um sinal de **overfitting**.\n",
    "\n",
    "Para este exercício, você tem `my_forest` e `my_tree_two` disponíveis para você. Os arrays `features` e `target` também estão prontos para uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore o atributo feature_importances_ e mostre na tela\n",
    "\n",
    "print(my_tree_two.feature_importances_)\n",
    "print(my_forest.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare a pontuação média de precisão dos dois modelos\n",
    "# Calcular e imprimir a pontuação média de precisão para ambos os modelos\n",
    "\n",
    "print(my_tree_two.score(features_two, target))\n",
    "print(my_forest.score(features_two, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluir e submeter\n",
    "\n",
    "Com base em sua descoberta no exercício anterior, determine qual recurso foi mais importante e para qual modelo. Após este exercício final, você poderá enviar seu modelo de floresta aleatória para o Kaggle! \n",
    "Use `my_forest`, `my_tree_two` e `feature_importances_` para responder a pergunta.\n",
    "\n",
    "Resp .: O atributo mais importante foi `Sex`, mas foi mais significativo para o modelo `my_tree_two`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
